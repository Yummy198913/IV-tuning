<div align="center">
<h1>IV-tuning: Parameter-Efficient Transfer Learning <br>
for Infrared-Visible Tasks</h1>


The official implemention for IV-tuning: Parameter-Efficient Transfer Learning for Infrared-Visible Tasks

paperï¼šhttps://arxiv.org/abs/2412.16654
</div>

## Introduction

IV-tuning is an efficient and effective Parameter-Efficient Transfer Learning (**PETL**) method for Infrared-Visible (**IR-VIS**) tasks. With approximately 3% of the backbone parameters trainable, IV-tuning achieves SOTA performance compared to previous IR-VIS methods, including Image Fusion methods and end-to-end IR-VIS methods in **Salient Object Detection**, **Object Detection** and **Semantic Segmentation**.

## Framework

<img width="1528" height="679" alt="image" src="https://github.com/user-attachments/assets/c6f358bb-addc-4376-ab74-457aa73bfb2b" />

## Visual Results
### Salient Object Detection
![sod](https://github.com/user-attachments/assets/50a2cd6c-8fcf-43f6-a3be-5d53f1cd2c99)
### Semantic Segmentation
![seg](https://github.com/user-attachments/assets/b2e8f141-f79f-42ee-a75b-e11b91af43b5)
### Object Detection
![det](https://github.com/user-attachments/assets/be308278-bae8-41f6-be4a-36f700ae5a3a)

## Citation
If you find our work helpful, please cite our paper:

```
@article{zhang2024iv,
  title={IV-tuning: Parameter-Efficient Transfer Learning for Infrared-Visible Tasks},
  author={Zhang, Yaming and Gao, Chenqiang and Liu, Fangcen and Guo, Junjie and Wang, Lan and Peng, Xinggan and Meng, Deyu},
  journal={arXiv preprint arXiv:2412.16654},
  year={2024}
}
```



